import requests
import cloudscraper
from bs4 import BeautifulSoup

HEADERS = {
    "User-Agent":
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36"
}
BASE_URL = "https://berlinstartupjobs.com"

scraper = cloudscraper.create_scraper()  # returns a requests.Session object


def extract_berlin_jobs(keyword):
    url = f"{BASE_URL}/skill-areas/{keyword}/"
    response = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(response.text, "html.parser")
    jobs = soup.find_all("li", class_="bjs-jlid")

    results = []

    for job in jobs:
        job: Tag  #ì—ëŸ¬ ì‚­ì œ - jobì´ Tag íƒ€ì…ì„ì„ ëª…ì‹œ
        title = job.find("h4").text.strip()
        company = job.find("a", class_="bjs-jlid__b").text.strip()
        link = job.find("a")["href"]
        #description = job.find("div", class_="bjs-jlid__description").text.strip()

        # ğŸ’¡ ë”•ì…”ë„ˆë¦¬ë¡œ ì •ë¦¬
        job_info = {
            "title": title,
            "company": company,
            "link": link,
        }
        print("ì œëª©:", title)
        print("íšŒì‚¬:", company)
        print("ë§í¬:", link)
        #print("ì„¤ëª…:", description)

        results.append(job_info)
    return results
